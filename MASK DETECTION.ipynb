{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "531b0941",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imutils\n",
      "  Downloading imutils-0.5.4.tar.gz (17 kB)\n",
      "Building wheels for collected packages: imutils\n",
      "  Building wheel for imutils (setup.py): started\n",
      "  Building wheel for imutils (setup.py): finished with status 'done'\n",
      "  Created wheel for imutils: filename=imutils-0.5.4-py3-none-any.whl size=25860 sha256=00f70f4443cddbbd2b7b6321d52fe1edbd6511cfd6dc108bae1758d8e67afa45\n",
      "  Stored in directory: c:\\users\\lenovo\\appdata\\local\\pip\\cache\\wheels\\59\\1b\\52\\0dea905f8278d5514dc4d0be5e251967f8681670cadd3dca89\n",
      "Successfully built imutils\n",
      "Installing collected packages: imutils\n",
      "Successfully installed imutils-0.5.4\n"
     ]
    }
   ],
   "source": [
    "!pip install imutils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a82b218",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ec5a3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_LR = 1e-4\n",
    "EPOCHS = 20\n",
    "BS = 32\n",
    "\n",
    "DIRECTORY = r\"C:\\Users\\lenovo\\Downloads\\FACE MASK\\dataset\\data\"\n",
    "CATEGORIES = [\"with_mask\", \"without_mask\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af301b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(DIRECTORY, category)\n",
    "    for img in os.listdir(path):\n",
    "    \timg_path = os.path.join(path, img)\n",
    "    \timage = load_img(img_path, target_size=(224, 224))\n",
    "    \timage = img_to_array(image)\n",
    "    \timage = preprocess_input(image)\n",
    "\n",
    "    \tdata.append(image)\n",
    "    \tlabels.append(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78bbefee",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels)\n",
    "\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "labels = np.array(labels)\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
    "\ttest_size=0.20, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be0790b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(\n",
    "\trotation_range=20,\n",
    "\tzoom_range=0.15,\n",
    "\twidth_shift_range=0.2,\n",
    "\theight_shift_range=0.2,\n",
    "\tshear_range=0.15,\n",
    "\thorizontal_flip=True,\n",
    "\tfill_mode=\"nearest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a7dead1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9412608/9406464 [==============================] - 13s 1us/step\n"
     ]
    }
   ],
   "source": [
    "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
    "\tinput_tensor=Input(shape=(224, 224, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "957f066e",
   "metadata": {},
   "outputs": [],
   "source": [
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(2, activation=\"softmax\")(headModel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc1b6bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=baseModel.input, outputs=headModel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "debb4744",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in baseModel.layers:\n",
    "\tlayer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21ff4b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] compiling model...\")\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed2f5d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training head...\n",
      "Epoch 1/20\n",
      "34/34 [==============================] - 54s 2s/step - loss: 0.5029 - accuracy: 0.7584 - val_loss: 0.1558 - val_accuracy: 0.9420\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 54s 2s/step - loss: 0.1545 - accuracy: 0.9504 - val_loss: 0.0832 - val_accuracy: 0.9710\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 61s 2s/step - loss: 0.0766 - accuracy: 0.9803 - val_loss: 0.0568 - val_accuracy: 0.9819\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 68s 2s/step - loss: 0.0587 - accuracy: 0.9831 - val_loss: 0.0439 - val_accuracy: 0.9891\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 64s 2s/step - loss: 0.0439 - accuracy: 0.9897 - val_loss: 0.0404 - val_accuracy: 0.9855\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 53s 2s/step - loss: 0.0506 - accuracy: 0.9860 - val_loss: 0.0310 - val_accuracy: 0.9928\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 54s 2s/step - loss: 0.0281 - accuracy: 0.9972 - val_loss: 0.0270 - val_accuracy: 0.9928\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 56s 2s/step - loss: 0.0263 - accuracy: 0.9934 - val_loss: 0.0258 - val_accuracy: 0.9928\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 51s 2s/step - loss: 0.0192 - accuracy: 0.9944 - val_loss: 0.0202 - val_accuracy: 0.9964\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 56s 2s/step - loss: 0.0278 - accuracy: 0.9934 - val_loss: 0.0197 - val_accuracy: 0.9928\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 53s 2s/step - loss: 0.0230 - accuracy: 0.9925 - val_loss: 0.0169 - val_accuracy: 0.9964\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 56s 2s/step - loss: 0.0150 - accuracy: 0.9972 - val_loss: 0.0151 - val_accuracy: 0.9964\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 53s 2s/step - loss: 0.0150 - accuracy: 0.9953 - val_loss: 0.0139 - val_accuracy: 0.9964\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 56s 2s/step - loss: 0.0139 - accuracy: 0.9963 - val_loss: 0.0133 - val_accuracy: 0.9964\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 59s 2s/step - loss: 0.0163 - accuracy: 0.9953 - val_loss: 0.0122 - val_accuracy: 0.9964\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 57s 2s/step - loss: 0.0147 - accuracy: 0.9981 - val_loss: 0.0190 - val_accuracy: 0.9928\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 61s 2s/step - loss: 0.0098 - accuracy: 0.9981 - val_loss: 0.0115 - val_accuracy: 0.9964\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 59s 2s/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.0124 - val_accuracy: 0.9964\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 60s 2s/step - loss: 0.0127 - accuracy: 0.9972 - val_loss: 0.0105 - val_accuracy: 0.9964\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 61s 2s/step - loss: 0.0178 - accuracy: 0.9934 - val_loss: 0.0112 - val_accuracy: 0.9964\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] training head...\")\n",
    "H = model.fit(\n",
    "\taug.flow(trainX, trainY, batch_size=BS),\n",
    "\tsteps_per_epoch=len(trainX) // BS,\n",
    "\tvalidation_data=(testX, testY),\n",
    "\tvalidation_steps=len(testX) // BS,\n",
    "\tepochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "111869b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] evaluating network...\")\n",
    "predIdxs = model.predict(testX, batch_size=BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8fba1aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   with_mask       1.00      0.99      1.00       138\n",
      "without_mask       0.99      1.00      1.00       138\n",
      "\n",
      "    accuracy                           1.00       276\n",
      "   macro avg       1.00      1.00      1.00       276\n",
      "weighted avg       1.00      1.00      1.00       276\n",
      "\n",
      "[INFO] saving mask detector model...\n"
     ]
    }
   ],
   "source": [
    "predIdxs = np.argmax(predIdxs, axis=1)\n",
    "\n",
    "# show a nicely formatted classification report\n",
    "print(classification_report(testY.argmax(axis=1), predIdxs,\n",
    "\ttarget_names=lb.classes_))\n",
    "\n",
    "# serialize the model to disk\n",
    "print(\"[INFO] saving mask detector model...\")\n",
    "model.save(\"mask_detector.model\", save_format=\"h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79dcdf66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = EPOCHS\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8457c599",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "from imutils.video import VideoStream\n",
    "import numpy as np\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "404c966a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] starting video stream...\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8f66da7f910c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;31m# detect faces in the frame and determine if they are wearing a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[1;31m# face mask or not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[1;33m(\u001b[0m\u001b[0mlocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetect_and_predict_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfaceNet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaskNet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;31m# loop over the detected face locations and their corresponding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-8f66da7f910c>\u001b[0m in \u001b[0;36mdetect_and_predict_mask\u001b[1;34m(frame, faceNet, maskNet)\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[1;31m# in the above `for` loop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m                 \u001b[0mfaces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfaces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"float32\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaskNet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfaces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;31m# return a 2-tuple of the face locations and their corresponding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[0;32m    129\u001b[0m           method.__name__))\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1597\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1599\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1600\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    812\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def detect_and_predict_mask(frame, faceNet, maskNet):\n",
    "\t# grab the dimensions of the frame and then construct a blob\n",
    "\t# from it\n",
    "\t(h, w) = frame.shape[:2]\n",
    "\tblob = cv2.dnn.blobFromImage(frame, 1.0, (224, 224),\n",
    "\t\t(104.0, 177.0, 123.0))\n",
    "\n",
    "\t# pass the blob through the network and obtain the face detections\n",
    "\tfaceNet.setInput(blob)\n",
    "\tdetections = faceNet.forward()\n",
    "\tprint(detections.shape)\n",
    "\n",
    "\t# initialize our list of faces, their corresponding locations,\n",
    "\t# and the list of predictions from our face mask network\n",
    "\tfaces = []\n",
    "\tlocs = []\n",
    "\tpreds = []\n",
    "\n",
    "\t# loop over the detections\n",
    "\tfor i in range(0, detections.shape[2]):\n",
    "\t\t# extract the confidence (i.e., probability) associated with\n",
    "\t\t# the detection\n",
    "\t\tconfidence = detections[0, 0, i, 2]\n",
    "\n",
    "\t\t# filter out weak detections by ensuring the confidence is\n",
    "\t\t# greater than the minimum confidence\n",
    "\t\tif confidence > 0.5:\n",
    "\t\t\t# compute the (x, y)-coordinates of the bounding box for\n",
    "\t\t\t# the object\n",
    "\t\t\tbox = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "\t\t\t(startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "\t\t\t# ensure the bounding boxes fall within the dimensions of\n",
    "\t\t\t# the frame\n",
    "\t\t\t(startX, startY) = (max(0, startX), max(0, startY))\n",
    "\t\t\t(endX, endY) = (min(w - 1, endX), min(h - 1, endY))\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "\t\t\t# extract the face ROI, convert it from BGR to RGB channel\n",
    "\t\t\t# ordering, resize it to 224x224, and preprocess it\n",
    "\t\t\tface = frame[startY:endY, startX:endX]\n",
    "\t\t\tface = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "\t\t\tface = cv2.resize(face, (224, 224))\n",
    "\t\t\tface = img_to_array(face)\n",
    "\t\t\tface = preprocess_input(face)\n",
    "\n",
    "\t\t\t# add the face and bounding boxes to their respective\n",
    "\t\t\t# lists\n",
    "\t\t\tfaces.append(face)\n",
    "\t\t\tlocs.append((startX, startY, endX, endY))\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "\t# only make a predictions if at least one face was detected\n",
    "\tif len(faces) > 0:\n",
    "\t\t# for faster inference we'll make batch predictions on *all*\n",
    "\t\t# faces at the same time rather than one-by-one predictions\n",
    "\t\t# in the above `for` loop\n",
    "\t\tfaces = np.array(faces, dtype=\"float32\")\n",
    "\t\tpreds = maskNet.predict(faces, batch_size=32)\n",
    "\n",
    "\t# return a 2-tuple of the face locations and their corresponding\n",
    "\t# locations\n",
    "\treturn (locs, preds)\n",
    "\n",
    "# load our serialized face detector model from disk\n",
    "prototxtPath = r\"C:\\Users\\lenovo\\Downloads\\FACE MASK\\FaceMaskDetection-main\\face_detector\\deploy.prototxt\"\n",
    "weightsPath = r\"C:\\Users\\lenovo\\Downloads\\FACE MASK\\FaceMaskDetection-main\\face_detector\\res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "faceNet = cv2.dnn.readNet(prototxtPath, weightsPath)\n",
    "\n",
    "# load the face mask detector model from disk\n",
    "maskNet = load_model(\"mask_detector.model\")\n",
    "\n",
    "# initialize the video stream\n",
    "print(\"[INFO] starting video stream...\")\n",
    "vs = VideoStream(src=0).start()\n",
    "\n",
    "# loop over the frames from the video stream\n",
    "while True:\n",
    "\t# grab the frame from the threaded video stream and resize it\n",
    "\t# to have a maximum width of 400 pixels\n",
    "\tframe = vs.read()\n",
    "\tframe = imutils.resize(frame, width=400)\n",
    "\n",
    "\t# detect faces in the frame and determine if they are wearing a\n",
    "\t# face mask or not\n",
    "\t(locs, preds) = detect_and_predict_mask(frame, faceNet, maskNet)\n",
    "\n",
    "\t# loop over the detected face locations and their corresponding\n",
    "\t# locations\n",
    "\tfor (box, pred) in zip(locs, preds):\n",
    "\t\t# unpack the bounding box and predictions\n",
    "\t\t(startX, startY, endX, endY) = box\n",
    "\t\t(mask, withoutMask) = pred\n",
    "\n",
    "\t\t# determine the class label and color we'll use to draw\n",
    "\t\t# the bounding box and text\n",
    "\t\tlabel = \"Mask\" if mask > withoutMask else \"No Mask\"\n",
    "\t\tcolor = (0, 255, 0) if label == \"Mask\" else (0, 0, 255)\n",
    "\n",
    "\t\t# include the probability in the label\n",
    "\t\tlabel = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\n",
    "\n",
    "\t\t# display the label and bounding box rectangle on the output\n",
    "\t\t# frame\n",
    "\t\tcv2.putText(frame, label, (startX, startY - 10),\n",
    "\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
    "\t\tcv2.rectangle(frame, (startX, startY), (endX, endY), color, 2)\n",
    "\n",
    "\t# show the output frame\n",
    "\tcv2.imshow(\"Frame\", frame)\n",
    "\tkey = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "\t# if the `q` key was pressed, break from the loop\n",
    "\tif key == ord(\"q\"):\n",
    "\t\tbreak\n",
    "\n",
    "# do a bit of cleanup\n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a36d31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4763b520",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
